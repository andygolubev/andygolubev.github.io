<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Monitoring multiple k8s clusters on Digital Ocean with Prometheus and Grafana deployed using Terraform and Ansible role</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="../styles.css">
    </head>
    <body class="article-page">
        <div class="article-container">
            <h1>Monitoring multiple k8s clusters on Digital Ocean with Prometheus and Grafana deployed using Terraform and Ansible role </h1>
            <h2>Date: 27 August 2024</h2>

            <img src="logo.jpg" alt="logo">

            <h2>Introduction</h2>
            <p>The internet is full of ready-made solutions for every taste, but problems arise when they don't fit your needs. That's when it's time to come up with something custom.</p>

            <p>This time, the challenge was to collect metrics from two K8S clusters located in different VPCs.</p>
            
            <p>It seemed like a simple task:</p>
            
            <ul>
                <li>Set up a dedicated server for Prometheus.</li>
                <li>Create a VPC Peering connection.</li>
                <li>Deploy Prometheus in each cluster.</li>
                <li>Set up federation.</li>
            </ul>
            
            <p>However, the issue is that Digital Ocean Cloud doesn't support VPC Peering as of this writing (link to <a href="https://docs.digitalocean.com/reference/terraform/reference/resources/vpc_peering/">documentation</a>), meaning all metrics would leave the cloud, go to the internet, and then come back, causing unnecessary traffic costs.</p>
            
            <p>To avoid this, we had to come up with alternative solutions that would work for a small startup while avoiding extra expenses.</p>
            
            <h2>Solution</h2>
            <p>So, here's the solution I implemented.</p>
            
            <p>There are three VPCs. Two of them host the clusters, and the third one contains the supporting tools, including a server with Grafana.</p>
            
            <p>Grafana connects to each cluster and pulls data for the dashboard. This setup ensures that traffic only flows when the dashboard is being viewed. Authentication is handled at the ingress.</p>
            
            <img src="pic01-solution.jpg" alt="solution">
            
            <h2>Tools</h2>
            <p>For the implementation, I chose the following tools:</p>
            
            <ul>
                <li>Prometheus</li>
                <li>Grafana</li>
                <li>Loki</li>
                <li>Terraform</li>
                <li>Ansible role</li>
                <li>Nginx</li>
                <li>Docker Compose</li>
                <li>Ubuntu server on Droplet</li>
            </ul>
            
            <p>I use Terraform to provision the server for the subsequent Grafana installation, as well as to create DNS records.</p>
            
            <p>I use an Ansible role to configure the server, including the installation and launch of all necessary services:</p>
            
            <ul>
                <li>Certbot</li>
                <li>Docker</li>
                <li>Nginx</li>
                <li>Grafana dashboards</li>
            </ul>
            
            <p>Prometheus and Grafana Loki are installed in the K8S clusters, from where the metrics and logs are collected.</p>
            
            <h2>The Code</h2>
            <p>I have a standard Ansible role written with tasks and templates to automate the setup and configuration.</p>
            
            <pre>
➜  monitoring-prometheus git:(main) tree monitoring_role 
monitoring_role
├── README.md
├── defaults
│   └── main.yml
├── files
│   ├── grafana-k8s-cluster-dashboard.json
│   ├── grafana-k8s-logs-dashboard.json
│   └── grafana-k8s-volumes-dashboard.json
├── handlers
│   └── main.yml
├── meta
│   └── main.yml
├── tasks
│   ├── 01_wait_for_initialization.yml
│   ├── 02_install_certbot_and_configure_nginx.yml
│   ├── 03_install_docker.yml
│   ├── 04_add_monitoring_user.yml
│   ├── 05_copy_configuration_files.yml
│   ├── 06_run_containers.yml
│   ├── 07_enable_ufw.yml
│   └── main.yml
├── templates
│   ├── dashboards.yaml.j2
│   ├── datasources.yaml.j2
│   ├── default.j2
│   └── docker-compose.yml.j2
├── tests
│   ├── inventory
│   └── test.yml
└── vars
    └── main.yml
            </pre>
            
            <p>The Ansible role handles the issuance of certificates, installs Nginx, sets up Grafana with dashboards, and starts Docker compose.</p>
            
            <h2>Result</h2>
            <p>Here is an example of how the final dashboard looks:</p>
            
            <img src="pic02-grafana.jpg" alt="dashboard">
            
            <h2>Conclusion</h2>
            <p>You don't always need to rely on out-of-the-box solutions, especially when they don't fit your needs. With a bit of creativity and the right open-source tools, you can build a custom solution that’s both effective and cost-efficient. In this case, combining Prometheus, Grafana, Loki, and a few other tools, I managed to set up a reliable monitoring system that works perfectly for a small startup without breaking the bank.</p>
            
            <p>I hope you enjoyed this article.</p>
            
            <p>You can find all of my code in my GitHub repository: <a href="https://github.com/andygolubev/monitoring-prometheus">https://github.com/andygolubev/monitoring-prometheus</a></p>
            
            <p>Feel free to connect with me on LinkedIn: <a href="https://www.linkedin.com/in/andy-golubev/">https://www.linkedin.com/in/andy-golubev/</a></p>
 
        </div>
    </body>
</html>






